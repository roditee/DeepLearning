{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wine_Quality_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rExThqhKXS_q"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset): \n",
        "  def __init__(self, phase='train'):\n",
        "   # 데이터 읽기\n",
        "   f = pd.read_csv('wine.csv')\n",
        "   data = f.to_numpy()\n",
        "   if phase=='train':\n",
        "     data=data[:1200,:]\n",
        "   if phase=='val':\n",
        "     data=data[1201:,:]\n",
        "\n",
        "   # 전처리\n",
        "   self.x_data = np.array(data[:,0:11], dtype=np.float)\n",
        "   self.x_data = ( self.x_data -  self.x_data.min(axis=0)) / ( self.x_data.max(axis=0) -  self.x_data.min(axis=0))\n",
        "\n",
        "   self.y_data = data[:, 11:12]\n",
        "   self.y_data[self.y_data=='bad']=0\n",
        "   self.y_data[self.y_data=='good']=1\n",
        "   self.y_data=np.array(self.y_data, dtype=np.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  def __getitem__(self, idx): \n",
        "    x = torch.Tensor(self.x_data[idx])\n",
        "    y = torch.LongTensor(self.y_data[idx])\n",
        "    return x, y\n",
        "\n",
        "batch_=10\n",
        "dataloader ={ 'train' :  DataLoader(CustomDataset(phase='train'), batch_size=batch_, shuffle=True),\n",
        "               'val' :  DataLoader(CustomDataset(phase='val'), batch_size=batch_, shuffle=False)\n",
        " }\n",
        "\n",
        "\n",
        "## Define the NN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(11, 50)    \n",
        "        self.fc2 = nn.Linear(50, 20)   \n",
        "        self.fc3 = nn.Linear(20, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # flatten image input\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.softmax(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "model = Net() # 모델 구축\n",
        "loss_fn =  torch.nn.CrossEntropyLoss()  # 손실함수 \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 옵티마이저 매개변수 갱신\n",
        "\n",
        "nb_epochs = 400\n",
        "\n",
        "for epoch in range(0, nb_epochs):\n",
        "  avg_cost = 0\n",
        "  sample_size = 0\n",
        "  avg_cost_ = 0\n",
        "  sample_size_ = 0\n",
        "\n",
        "  # Train\n",
        "  for batch_idx, samples in enumerate(dataloader['train']):\n",
        "    x_train, y_train = samples\n",
        "\n",
        "    pred = model(x_train)\n",
        "    loss = loss_fn(pred, y_train[:,0])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    avg_cost+=loss\n",
        "    sample_size+=1\n",
        "\n",
        "  # Val\n",
        "  for batch_idx, samples in enumerate(dataloader['val']):\n",
        "    x_train, y_train = samples\n",
        "    pred = model(x_train)\n",
        "    loss = loss_fn(pred, y_train[:,0])\n",
        "    avg_cost_+=loss\n",
        "    sample_size_+=1\n",
        "  \n",
        "  print(\"epoch :\" , epoch, \"loss_train\", avg_cost/sample_size, \"loss_val\", avg_cost_/sample_size_ )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}