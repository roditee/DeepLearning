{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Corn_Leaf_Disease.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybJrk0CraR_8"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/AIdata/Leaf Disease Dataset')\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset): \n",
        "  def __init__(self, phase='train'):\n",
        "   # 데이터 읽기\n",
        "   self.dinfo = torchvision.datasets.ImageFolder(root='train')\n",
        "   self.data_transfroms=transforms.Compose([transforms.Resize((224,224)),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "  def __len__(self):\n",
        "    return len(self.dinfo.samples)\n",
        "\n",
        "  def __getitem__(self, idx): \n",
        "    x = Image.open(self.dinfo.imgs[idx][0])\n",
        "    x = self.data_transfroms(x)\n",
        "    y = torch.tensor(self.dinfo.imgs[idx][1])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        # ImgIn shape=(?, 256, 256, 1)\n",
        "    \n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 전결합층 7x7x64 inputs -> 4 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 4, bias=True)\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "batch_=100\n",
        "dataloader ={ 'train' :  DataLoader(CustomDataset(phase='train'), batch_size=batch_, shuffle=True),\n",
        "              # 'val' :  DataLoader(CustomDataset(phase='val'), batch_size=batch_, shuffle=False)\n",
        " }\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = CNN().to(device) # 모델 구축\n",
        "loss_fn =  torch.nn.CrossEntropyLoss()  # 손실함수 \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 옵티마이저 매개변수 갱신\n",
        "\n",
        "nb_epochs = 10\n",
        "for epoch in range(0, nb_epochs):\n",
        "  avg_cost = 0\n",
        "  sample_size = 0\n",
        "  avg_cost_ = 0\n",
        "  sample_size_ = 0\n",
        "\n",
        "  # Train\n",
        "  for batch_idx, samples in enumerate(dataloader['train']):\n",
        "    x_train, y_train = samples\n",
        "    x_train = x_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "\n",
        "    pred = model(x_train)\n",
        "    loss = loss_fn(pred, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost+=loss\n",
        "    sample_size+=1\n",
        "\n",
        "  print(\"epoch :\" , epoch, \"loss_train\", avg_cost/sample_size )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}